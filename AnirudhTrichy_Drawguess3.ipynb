{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14068851,"sourceType":"datasetVersion","datasetId":8955131}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n#Loads dataset and prints few rows\ntrain_df = pd.read_csv(\"/kaggle/input/drawguess/train_sent_emo.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/drawguess/test_sent_emo.csv\")\n\ntrain_df.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Sorts the dialogues in correct utterance order\ntrain_df = train_df.sort_values([\"Dialogue_ID\", \"Utterance_ID\"])\ntest_df  = test_df.sort_values([\"Dialogue_ID\", \"Utterance_ID\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\n\ndef create_windows(df):\n    X, y = [], []\n    #Groups by dialogue\n    grouped = df.groupby(\"Dialogue_ID\")\n    \n    for _, dialog in grouped:\n        #For each dialogue, ensures utterances are in order\n        dialog = dialog.sort_values(\"Utterance_ID\")\n\n        #Converts utterances and emotions in a dialogue to list\n        utts = dialog[\"Utterance\"].tolist()\n        emos = dialog[\"Emotion\"].tolist()\n        \n        for i in range(len(utts) - 4):\n            #Takes a size 5 subset of the utts and emos lists for window\n            window_utts = utts[i:i+5]\n            window_emos = emos[i:i+5]\n            \n            #Counts occurances of each emotion in window then picks the top(majority)\n            counts = Counter(window_emos)\n            top = counts.most_common()\n\n            #Ignores the window is there is tie in majority emotion\n            if len(top) > 1 and top[0][1] == top[1][1]:\n                continue  \n            #Adds the window to the list of all windows(input)\n            X.append(window_utts)\n            #Adds the emotion(label) to list of all emotions(output)\n            y.append(top[0][0])\n    \n    return X, y\n#Gets input,output for the RNN using above function\ntrain_windows, train_labels = create_windows(train_df)\ntest_windows, test_labels = create_windows(test_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef clean_text(s):\n    #Converts to lower case and only keeps the character given(discards other chars - replaces with \"\")\n    s = s.lower()\n    s = re.sub(r\"[^a-z0-9.,!? ]\", \"\", s)\n    return s\n\ndef combine_window(window):\n    #Applies above clean function for each utterance in a window and puts it in a list.\n    #Then elements of the list are seperated with a \"<SEP>\"\n    return \" <SEP> \".join([clean_text(u) for u in window])\n#Applies above function for each window.\n#So output will be a list where every element is a single string consisting of the 5 utterances in a window seperated by \"<SEP>\"\ntrain_texts = [combine_window(w) for w in train_windows]\ntest_texts  = [combine_window(w) for w in test_windows]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\nidx = 2\n#Loops through all texts in train_texts \nfor text in train_texts:\n    #Loops through each word in a text(split into seperate words)\n    for w in text.split():\n        #Adds every unique word to dictionary and assigns it an integer value(idx)\n        if w not in word2idx:\n            word2idx[w] = idx\n            idx += 1\n#Returns size of dictionary including the pad and unk\nvocab_size = len(word2idx)\nvocab_size","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nMAX_LEN = 80  #defines length of each sqeuence\n\ndef encode(text):\n    tokens = text.split()#Split the text sequence into list of words\n    ids = [word2idx.get(t, 1) for t in tokens]#Get the index for each word in tokens from above dictionary(if word not present let index be 1(UNK))\n    if len(ids) < MAX_LEN:\n        ids += [0] * (MAX_LEN - len(ids)) #Pads index with 0 until it reaches max length\n    return ids[:MAX_LEN] #Returns only max length number \n\n#Creates tensor for each window string(number of window strings,80) in both train and test\nX_train = torch.tensor([encode(t) for t in train_texts])\nX_test  = torch.tensor([encode(t) for t in test_texts])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Assigns an integer to each unique emotion\nemotion2idx = {e: i for i, e in enumerate(sorted(set(train_labels)))}\n#Reverse - maps the emotion with its integer\nidx2emotion = {i: e for e, i in emotion2idx.items()}\n\n#Get tensors of emotions converted into their labels(integers)\ny_train = torch.tensor([emotion2idx[e] for e in train_labels])\ny_test  = torch.tensor([emotion2idx[e] for e in test_labels])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#Splits training data into 90% for training and 10% for valuation(not same as testing)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.1, random_state=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nclass SimpleRNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.embed(x)\n        out, hidden = self.rnn(x)\n        return self.fc(hidden.squeeze(0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\nbatch_size = 32\n#Creates batches of data\ntrain_loader = DataLoader(TensorDataset(X_train, y_train), batch_size, shuffle=True)\nval_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size)\n#Instantiates the model\nmodel = SimpleRNNClassifier(\n    vocab_size=vocab_size,\n    embed_dim=100,\n    hidden_dim=128,\n    num_classes=len(emotion2idx)\n)\n#Uses cross entropy for loss\ncriterion = nn.CrossEntropyLoss()\n#Uses Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n#Training loop\nfor epoch in range(10):\n    #Training mode\n    model.train()\n    total, correct, total_loss = 0, 0, 0\n\n    for xb, yb in train_loader:\n        optimizer.zero_grad() #Resets gradients\n        logits = model(xb) #Runs input through model and gets output\n        loss = criterion(logits, yb) #Computes loss \n        loss.backward() #Backprop\n        optimizer.step() #Optimizes parameters\n\n        total_loss += loss.item() #Adds loss in each run\n        preds = logits.argmax(1) #Gets highest value from output(logits)\n        correct += (preds == yb).sum().item() #Checks how many were correct predictions from output\n        total += len(yb)\n    #Keeps track of loss and accuracy \n    train_losses.append(total_loss / len(train_loader)) \n    train_accs.append(correct / total)\n\n    #Validation mode(all steps same as above but only validation - no updation of paramaters)\n    model.eval()\n    v_total, v_correct, v_loss = 0, 0, 0\n    \n    with torch.no_grad():\n        for xb, yb in val_loader:\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            v_loss += loss.item()\n            preds = logits.argmax(1)\n            v_correct += (preds == yb).sum().item()\n            v_total += len(yb)\n\n    val_losses.append(v_loss / len(val_loader))\n    val_accs.append(v_correct / v_total)\n\n    print(f\"Epoch {epoch+1} | Train Acc: {train_accs[-1]:.3f} | Val Acc: {val_accs[-1]:.3f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n#Computes f1 score after putting model in validation mode\nmodel.eval()\npreds = []\n\nwith torch.no_grad():\n    for xb, _ in val_loader:\n        preds.extend(model(xb).argmax(1).tolist()) #List of all prediction\n\nmacro_f1 = f1_score(y_val.tolist(), preds, average=\"macro\")\nprint(\"Macro F1:\", macro_f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Till now we had used the simple RNN model - hence validation accuracy did not improve and remained low and constant. Now we try to improve","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass ImprovedRNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n        super().__init__()\n        \n        # Bigger embedding dimension(from 100 → 200)\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        \n        # Same RNN structure\n        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n        \n        # Dropout added → reduces overfitting\n        self.dropout = nn.Dropout(0.4)\n        \n        # Final classifier\n        self.fc = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.embed(x)              # (batch, seq, embed_dim)\n        out, hidden = self.rnn(x)      # hidden: (1, batch, hidden_dim)\n        hidden = hidden.squeeze(0)     # (batch, hidden_dim)\n        hidden = self.dropout(hidden)  # Apply dropout\n        logits = self.fc(hidden)       # (batch, num_classes)\n        return logits\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ImprovedRNN(\n    vocab_size=vocab_size,\n    embed_dim=200,       # increased from 100\n    hidden_dim=128,\n    num_classes=len(emotion2idx)\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n#Training loop\nfor epoch in range(10):\n    #Training mode\n    model.train()\n    total, correct, total_loss = 0, 0, 0\n\n    for xb, yb in train_loader:\n        optimizer.zero_grad() #Resets gradients\n        logits = model(xb) #Runs input through model and gets output\n        loss = criterion(logits, yb) #Computes loss \n        loss.backward() #Backprop\n        optimizer.step() #Optimizes parameters\n\n        total_loss += loss.item() #Adds loss in each run\n        preds = logits.argmax(1) #Gets highest value from output(logits)\n        correct += (preds == yb).sum().item() #Checks how many were correct predictions from output\n        total += len(yb)\n    #Keeps track of loss and accuracy \n    train_losses.append(total_loss / len(train_loader)) \n    train_accs.append(correct / total)\n\n    #Validation mode(all steps same as above but only validation - no updation of paramaters)\n    model.eval()\n    v_total, v_correct, v_loss = 0, 0, 0\n    \n    with torch.no_grad():\n        for xb, yb in val_loader:\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            v_loss += loss.item()\n            preds = logits.argmax(1)\n            v_correct += (preds == yb).sum().item()\n            v_total += len(yb)\n\n    val_losses.append(v_loss / len(val_loader))\n    val_accs.append(v_correct / v_total)\n\n    print(f\"Epoch {epoch+1} | Train Acc: {train_accs[-1]:.3f} | Val Acc: {val_accs[-1]:.3f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-09T06:51:47.611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Computes f1 score after putting model in validation mode\nmodel.eval()\npreds = []\n\nwith torch.no_grad():\n    for xb, _ in val_loader:\n        preds.extend(model(xb).argmax(1).tolist()) #List of all prediction\n\nmacro_f1 = f1_score(y_val.tolist(), preds, average=\"macro\")\nprint(\"Macro F1:\", macro_f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}